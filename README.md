# HPC-Matrix

## Matrix Preprocessing

Starting with the serial approach, we need to scan each element of the matrix and calculate the neighborhood average for each element using a 3x3 filter. Then, we compute the anomaly index σ for that element. If it is greater than 0.1, we replace it with the neighborhood average; otherwise, it remains unchanged. For the matrix content about to be preprocessed, each row depends on the two rows above and below it, but the boundaries (e.g., the first row) can only depend on the row below. Thus, different rows need to be treated differently. With this understanding, we can proceed with matrix splitting and distribution. For the middle part of the matrix, when passing it to the child processes, we can also include the preceding and succeeding rows. However, for the first row of the matrix, we need to avoid accessing the -1st row to prevent memory access exceptions that may terminate the process. My approach is to check whether the first row of the sub-matrix to be transmitted is the same as the first row of the main matrix. If it is, then we do not transmit the content of the preceding row; otherwise, we transmit it. Next, we use a for loop to transmit the main body of the sub-matrix to the child processes. Finally, we check whether the last row of the sub-matrix is the same as the last row of the main matrix. If it is, then we do not transmit the content of the succeeding row; otherwise, we transmit it. The second part involves the child processes handling the received matrices. This part constitutes the core of the algorithm and consumes the major computational resources. The basic algorithm idea is to receive the sub-matrix passed in by the parent process and deduce which rows are for preprocessing and which rows are for assisting the preprocessing based on the dimension information of the parent matrix and the rank value of the child process. Based on this, we need to traverse each target element, calculate the neighborhood average following the serial preprocessing method, and determine whether to overwrite the target element with the neighborhood average (i.e., obtaining the value of σ).

## Generic Matrix Multiplication

In the main process, the first step is initialization, generating matrices A and B. Then, the MPI_Bcast function is used to broadcast matrix B to all processes. Subsequently, the MPI_Scatter function is utilized to send matrix A in blocks to each child process. In each child process, the received matrix blocks and matrix B are multiplied, and the calculation results are stored locally. After that, the main process employs the MPI_Gather function to collect the calculation results from all child processes and concatenate them to obtain the resulting matrix. Finally, the matrix multiplication is completed, and the process ends. Through parallel computation, data distribution, and collection, efficient MPI-based matrix multiplication is achieved. Additionally, it is important to note that during the process of matrix block distribution, due to the initial strategy of evenly dividing rows based on the number of processes, there might be some rows that cannot be evenly divided among the processes, resulting in a remainder. These remaining rows will be calculated by the main process after it receives all the computation results from the child processes.

## Sparse Matrix Multiplication

To use the sparse matrix algorithm, it is necessary to investigate the representation methods for sparse matrices. After conducting research, I found three storage methods, namely triplet sequence, row-wise linked list, and cross-linked list. For this course project, I chose to use the row-wise linked list structure to store the sparse matrix.

The process of storing a sparse matrix using the row-wise linked list can also be referred to as matrix compression. For medium to large-sized matrices with a significant number of zeros, we can use a sparse matrix to store them, thereby reducing the space overhead of a matrix in a computer. Now, I will introduce the basic implementation principles of the sparse matrix algorithm.

The implementation process of row-wise linked list and triplet sequence is similar. They both store the matrix by representing the triplet (row index, column index, and element value) of non-zero elements in a one-dimensional array. However, to improve the efficiency of extracting and searching non-zero elements of a specific row, the row-wise linked list method uses an additional array to record the position of the first non-zero element in each row within the one-dimensional array.